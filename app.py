import os
import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

load_dotenv()

def ask_llm(user_text: str, expert_type: str) -> str:
    if expert_type == "Aï¼šPython/Streamlitè¬›å¸«":
        system_prompt = (
            "ã‚ãªãŸã¯Pythonã¨Streamlitã®å°‚é–€è¬›å¸«ã§ã™ã€‚"
            "åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚‹ã‚ˆã†ã«ã€æ‰‹é †ã‚’ç®‡æ¡æ›¸ãã§ä¸å¯§ã«èª¬æ˜ã—ã€"
            "å¿…è¦ãªã‚‰çŸ­ã„ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚‚æç¤ºã—ã¦ãã ã•ã„ã€‚"
        )
    else:
        system_prompt = (
            "ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆä¼ç”»ã®ãƒ¡ãƒ³ã‚¿ãƒ¼ã§ã™ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼èª²é¡Œã®æ•´ç†ã€ä»®èª¬ã€å„ªå…ˆé †ä½ã€MVPè¨­è¨ˆã®è¦³ç‚¹ã§ã€"
            "å®Ÿå‹™çš„ã«åŠ©è¨€ã—ã¦ãã ã•ã„ã€‚"
        )

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="ã“ã‚Œã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚"),
        AIMessage(content="æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚è³ªå•ã‚’ã©ã†ãã€‚"),
        HumanMessage(content=user_text),
    ]

    result = llm.invoke(messages)
    return result.content


def main():
    st.set_page_config(page_title="LangChain Ã— Streamlit Demo", page_icon="ğŸ¤–", layout="centered")
    st.title("ğŸ¤– LangChain Ã— Streamlitï¼ˆå°‚é–€å®¶åˆ‡ã‚Šæ›¿ãˆãƒ‡ãƒ¢ï¼‰")

    st.markdown(
        """
ã“ã®Webã‚¢ãƒ—ãƒªã¯ã€å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ã™ã‚‹ã¨ã€LangChainçµŒç”±ã§LLMã«å•ã„åˆã‚ã›ã¦å›ç­”ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚  
ã¾ãŸã€ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ **LLMã«æŒ¯ã‚‹èˆã‚ã›ã‚‹å°‚é–€å®¶** ã‚’åˆ‡ã‚Šæ›¿ãˆã§ãã¾ã™ã€‚

### ä½¿ã„æ–¹
1. ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ï¼ˆA/Bï¼‰ã‚’é¸æŠ  
2. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›  
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™ã¨ã€å›ç­”ãŒç”»é¢ä¸‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™
"""
    )

    if not os.getenv("OPENAI_API_KEY"):
        st.warning("ç’°å¢ƒå¤‰æ•° `OPENAI_API_KEY` ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šå¾Œã«å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    expert_type = st.radio(
        "å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=["Aï¼šPython/Streamlitè¬›å¸«", "Bï¼šãƒ—ãƒ­ãƒ€ã‚¯ãƒˆä¼ç”»ãƒ¡ãƒ³ã‚¿ãƒ¼"],
        horizontal=True,
    )

    user_text = st.text_input(
        "å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆè³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼‰",
        placeholder="ä¾‹ï¼šStreamlitã§å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½œã‚‹æ–¹æ³•ã¯ï¼Ÿ",
    )

    if st.button("é€ä¿¡", type="primary", use_container_width=True):
        if not user_text.strip():
            st.error("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            try:
                answer = ask_llm(user_text=user_text, expert_type=expert_type)
            except Exception as e:
                st.error(f"LLMå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.stop()

        st.subheader("å›ç­”")
        st.write(answer)


if __name__ == "__main__":
    main()